{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feat_count(df,feat):\n",
    "    feat_count = df.groupby([feat]).size().reset_index()\n",
    "    feat_count.columns = [feat,'%s_count'%(feat)]\n",
    "    df = df.merge(feat_count,how='left',on=[feat])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the test and training data\n",
    "train = pd.read_csv(\"group-income-train.csv\")\n",
    "test = pd.read_csv(\"group-income-test.csv\")\n",
    "data = pd.concat([train,test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (2,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Coverting Additional Income to Ints for Easier Processing\n",
    "data['Yearly Income in addition to Salary (e.g. Rental Income)'] = data['Yearly Income in addition to Salary (e.g. Rental Income)'].map(lambda x:x.replace(' EUR',''))\n",
    "data['Yearly Income in addition to Salary (e.g. Rental Income)'] = data['Yearly Income in addition to Salary (e.g. Rental Income)'].astype(float)\n",
    "data['Yearly Income in addition to Salary (e.g. Rental Income)']=data['Yearly Income in addition to Salary (e.g. Rental Income)'].astype(int)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding all Necessary Columns for Processing along with creating a feature count col\n",
    "cols = data.columns.tolist()\n",
    "feat_cols = [col for col in data.columns if col not in ['Instance','Total Yearly Income [EUR]']]\n",
    "for col in feat_cols:\n",
    "    data = create_feat_count(data,col)\n",
    "feat_cols = [col for col in data.columns if col not in ['Instance','Total Yearly Income [EUR]']]\n",
    "obj_col = data[feat_cols].dtypes[data[feat_cols].dtypes == 'object'].index.tolist()\n",
    "for col in obj_col:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our nicely formatted data back into test and training sets\n",
    "train = data[data['Total Yearly Income [EUR]'].notnull()]\n",
    "test = data[data['Total Yearly Income [EUR]'].isnull()]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Using cached https://files.pythonhosted.org/packages/05/ec/756f13b25258e0aa6ec82d98504e01523814f95fc70718407419b8520e1d/lightgbm-2.3.0-py2.py3-none-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from lightgbm) (1.14.5)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages (from lightgbm) (0.20.3)\n",
      "\u001b[31mtyping-extensions 3.7.4.1 has requirement typing>=3.7.4; python_version < \"3.5\", but you'll have typing 3.6.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's l1: 8679.88\tvalid_1's l1: 8853.34\n",
      "[2000]\ttraining's l1: 8233.09\tvalid_1's l1: 8493.82\n",
      "[3000]\ttraining's l1: 7969.92\tvalid_1's l1: 8319.73\n",
      "[4000]\ttraining's l1: 7767.84\tvalid_1's l1: 8210.76\n",
      "[5000]\ttraining's l1: 7605.47\tvalid_1's l1: 8141.13\n",
      "[6000]\ttraining's l1: 7472.62\tvalid_1's l1: 8090.25\n",
      "[7000]\ttraining's l1: 7355.37\tvalid_1's l1: 8051.32\n",
      "[8000]\ttraining's l1: 7239.3\tvalid_1's l1: 8022.13\n",
      "[9000]\ttraining's l1: 7132.37\tvalid_1's l1: 7998.57\n",
      "[10000]\ttraining's l1: 7034.02\tvalid_1's l1: 7981.21\n",
      "[11000]\ttraining's l1: 6938.42\tvalid_1's l1: 7961.07\n",
      "[12000]\ttraining's l1: 6854.89\tvalid_1's l1: 7949.37\n",
      "[13000]\ttraining's l1: 6767.37\tvalid_1's l1: 7937.65\n",
      "[14000]\ttraining's l1: 6686.68\tvalid_1's l1: 7928.79\n",
      "[15000]\ttraining's l1: 6610.69\tvalid_1's l1: 7919.51\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[15000]\ttraining's l1: 6610.69\tvalid_1's l1: 7919.51\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's l1: 8677.52\tvalid_1's l1: 8764.23\n",
      "[2000]\ttraining's l1: 8241.4\tvalid_1's l1: 8426.2\n",
      "[3000]\ttraining's l1: 7986.51\tvalid_1's l1: 8271.98\n",
      "[4000]\ttraining's l1: 7779.33\tvalid_1's l1: 8151.87\n",
      "[5000]\ttraining's l1: 7622.14\tvalid_1's l1: 8085.35\n",
      "[6000]\ttraining's l1: 7488.79\tvalid_1's l1: 8040.4\n",
      "[7000]\ttraining's l1: 7361.01\tvalid_1's l1: 7995.73\n",
      "[8000]\ttraining's l1: 7246.81\tvalid_1's l1: 7966.76\n",
      "[9000]\ttraining's l1: 7141.79\tvalid_1's l1: 7943.47\n",
      "[10000]\ttraining's l1: 7042.27\tvalid_1's l1: 7922.37\n",
      "[11000]\ttraining's l1: 6948.45\tvalid_1's l1: 7904.33\n",
      "[12000]\ttraining's l1: 6866.39\tvalid_1's l1: 7889.67\n",
      "[13000]\ttraining's l1: 6784.44\tvalid_1's l1: 7878.28\n",
      "[14000]\ttraining's l1: 6705.8\tvalid_1's l1: 7869.38\n",
      "[15000]\ttraining's l1: 6630.35\tvalid_1's l1: 7860.46\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[15000]\ttraining's l1: 6630.35\tvalid_1's l1: 7860.46\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[1000]\ttraining's l1: 8681.21\tvalid_1's l1: 8855.95\n",
      "[2000]\ttraining's l1: 8241.45\tvalid_1's l1: 8506.66\n",
      "[3000]\ttraining's l1: 7979.75\tvalid_1's l1: 8331.18\n",
      "[4000]\ttraining's l1: 7777.57\tvalid_1's l1: 8220.18\n",
      "[5000]\ttraining's l1: 7614.21\tvalid_1's l1: 8148.44\n",
      "[6000]\ttraining's l1: 7479.13\tvalid_1's l1: 8095.99\n",
      "[7000]\ttraining's l1: 7356.7\tvalid_1's l1: 8061.58\n",
      "[8000]\ttraining's l1: 7236.01\tvalid_1's l1: 8033.25\n",
      "[9000]\ttraining's l1: 7128.22\tvalid_1's l1: 8011.08\n",
      "[10000]\ttraining's l1: 7029.02\tvalid_1's l1: 7993.59\n",
      "[11000]\ttraining's l1: 6937.05\tvalid_1's l1: 7974.23\n",
      "[12000]\ttraining's l1: 6847.15\tvalid_1's l1: 7959.72\n",
      "[13000]\ttraining's l1: 6765.22\tvalid_1's l1: 7949.56\n",
      "[14000]\ttraining's l1: 6686.75\tvalid_1's l1: 7940.33\n",
      "[15000]\ttraining's l1: 6610.43\tvalid_1's l1: 7931.93\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[15000]\ttraining's l1: 6610.43\tvalid_1's l1: 7931.93\n"
     ]
    }
   ],
   "source": [
    "# This messy pip install was for convenience when running on Google Colab/AWS Sagemaker:\n",
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Running a k-fold cross validation as in:\n",
    "# https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "# Using tweedie distribution with gdbt boosting\n",
    "params = {\n",
    "          'max_depth': 30,\n",
    "          'learning_rate': 0.02,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'objective':'tweedie',\n",
    "          'gpu_platform_id': 0,\n",
    "          'gpu_device_id': 0,\n",
    "          'num_iterations' : 200000,\n",
    "         }\n",
    "# N-folds opted for 5, according to researched material online 5 or 10 can be ideal for this process\n",
    "folds = 5\n",
    "seed = 2019\n",
    "pre_sub = pd.DataFrame()\n",
    "kf = StratifiedKFold(n_splits=folds,shuffle=True,random_state=seed)\n",
    "ix = 0\n",
    "for tr_idx,val_idx in kf.split(train,train['Country']):\n",
    "    x_train,y_train = train[feat_cols].iloc[tr_idx],train['Total Yearly Income [EUR]'].iloc[tr_idx]\n",
    "    x_val,y_val = train[feat_cols].iloc[val_idx],train['Total Yearly Income [EUR]'].iloc[val_idx]\n",
    "    trn_data = lgb.Dataset(x_train, label=y_train)\n",
    "    val_data = lgb.Dataset(x_val, label=y_val)\n",
    "    # 15000 Redundant now as overridden with num_iterations\n",
    "    clf = lgb.train(params, trn_data, 15000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=500)\n",
    "    test_pre = clf.predict(test[feat_cols])\n",
    "    pre_sub[ix] = test_pre\n",
    "    ix += 1\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the mean of 5-fold cross validation and using as answer\n",
    "pre_sub['sum'] = pre_sub[[0,1,2,3,4]].mean(axis=1)\n",
    "pre_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing resolves to CSV\n",
    "sub = pd.DataFrame()\n",
    "sub['Instance'] = test['Instance'].tolist()\n",
    "sub['Total Yearly Income [EUR]'] = pre_sub['sum'].values\n",
    "sub.to_csv(\"awssubmission.csv\",index=False)\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
